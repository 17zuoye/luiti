{"name":"Luiti","tagline":"luiti = luigi + time.","body":"Luiti\r\n========================\r\n[![Build Status](https://img.shields.io/travis/17zuoye/luiti/master.svg?style=flat)](https://travis-ci.org/17zuoye/luiti)\r\n[![Coverage Status](https://coveralls.io/repos/17zuoye/luiti/badge.svg)](https://coveralls.io/r/17zuoye/luiti)\r\n[![Health](https://landscape.io/github/17zuoye/luiti/master/landscape.svg?style=flat)](https://landscape.io/github/17zuoye/luiti/master)\r\n[![Download](https://img.shields.io/pypi/dm/luiti.svg?style=flat)](https://pypi.python.org/pypi/luiti)\r\n[![License](https://img.shields.io/pypi/l/luiti.svg?style=flat)](https://pypi.python.org/pypi/luiti)\r\n[![Python Versions](https://pypip.in/py_versions/luiti/badge.svg?style=flat)](https://pypi.python.org/pypi/luiti)\r\n\r\nAs [Luigi](https://github.com/spotify/luigi)'s homepage said, it's \"a\r\nPython module that helps you build complex pipelines of batch jobs. It\r\nhandles dependency resolution, workflow management, visualization etc.\r\nIt also comes with Hadoop support built in.\"\r\n\r\nLuiti is built on top of Luigi, separates all your tasks into multiple\r\npackages, and forces one task per one Python file. Luiti task classes\r\ncan be managed by the `luiti` command, supported operations are ls, new,\r\ngenerate, info, clean, and run.\r\n\r\nLuiti is born to build a layered database structure, corresponding to\r\nthe different packages we just mentioned. A data warehouse is consisted\r\nof synced data sources, fact tables, dimension tables, regular or\r\ntemporary business reports.\r\n\r\nThe essence of batching processing system is to separating a large task\r\ninto small tasks, and the essence of business report is that a daily\r\nreport or a weekly report is requried, so here comes TaskDay, TaskWeek,\r\nand more. Task classes also have a Hadoop version, such as TaskDayHadoop,\r\nTaskWeekHadoop, and so on.\r\n\r\nYou can pass any parameters into Luigi's tasks, but Luiti recommend you\r\nto pass only `date_value` parameter. So you can run Luiti tasks\r\nperiodically, e.g. hourly, daily, weekly, etc. luiti = luigi + time.\r\n\r\n\r\nA simple guide to Luigi\r\n------------------------\r\nLuigi's core concept is forcing you separting a big task into many small\r\ntasks, and they're linked by atomic Input and Ouput. Luigi contains four\r\nparts mainly:\r\n\r\n1. Output. It must be implemented in `output` function, such as `LocalTarget` and `hdfs.HdfsTarget`.\r\n2. Input. It must be implemented in `requires` function, and the\r\n  function supposed to return some or None task instances.\r\n3. Parameters. Parameters should be inherited from `luigi.Parameter`,\r\n  e.g. `DateParameter`, etc.\r\n4. Execute Logic. Use `run` function if running at local, or `mapper` and `reducer`\r\n  if running on a distributed MapReduce YARN.\r\n\r\nAfter finish the business logic implementation and test cases, You can\r\nsubmit your task to the `luigid` background daemon. `luigid` will\r\nprocess task dependencies automatically, this is done by checking\r\n`output` is already `exists` (It's the Target class's function). And\r\nluigi will guarantee that task instances are uniq in current\r\n`luigid` background process by the task class name and parameters.\r\n\r\nA simple example in luiti\r\n------------------------\r\n#### An official example from luigi.\r\nBelow code is copied from http://luigi.readthedocs.org/en/latest/example_top_artists.html\r\n\r\n```python\r\nimport luigi\r\nfrom collections import defaultdict\r\n\r\nclass AggregateArtists(luigi.Task):\r\n    date_interval = luigi.DateIntervalParameter()\r\n\r\n    def output(self):\r\n        return luigi.LocalTarget(\"/data/artist_streams_%s.tsv\" % self.date_interval)\r\n\r\n    def requires(self):\r\n        return [Streams(date) for date in self.date_interval]\r\n\r\n    def run(self):\r\n        artist_count = defaultdict(int)\r\n\r\n        for input in self.input():\r\n            with input.open('r') as in_file:\r\n                for line in in_file:\r\n                    timestamp, artist, track = line.strip().split()\r\n                    artist_count[artist] += 1\r\n\r\n        with self.output().open('w') as out_file:\r\n            for artist, count in artist_count.iteritems():\r\n                print >> out_file, artist, count\r\n```\r\n\r\n#### The same example written in luiti.\r\n\r\n* First file: `artist_project/luiti_tasks/artist_stream_day.py`\r\n\r\n```python\r\nfrom luiti import *\r\n\r\nclass ArtistStreamDay(StaticFile):\r\n\r\n    @cached_property\r\n    def filepath(self):\r\n        return TargetUtils.hdfs(\"/tmp/streams_%s.tsv\" % self.date_str\r\n```\r\n\r\n* Second file: `artist_project/luiti_tasks/aggregate_artists_week.py`\r\n```python\r\nfrom luiti import *\r\n\r\n@luigi.ref_tasks(\"ArtistStreamDay')\r\nclass AggregateArtistsWeek(TaskWeek):\r\n\r\n    def requires(self):\r\n        return [self.ArtistStreamDay(d1) for d1 in self.days_in_week]\r\n\r\n    def output(self):\r\n        return TargetUtils.hdfs(\"/data/artist_streams_%s.tsv\" % self.date_str\r\n\r\n    def run(self):\r\n        artist_count = defaultdict(int)\r\n\r\n        for file1 in self.input():\r\n            for line2 in TargetUtils.line_read(file1):\r\n                timestamp, artist, track = line.strip().split()\r\n                artist_count[artist] += 1\r\n\r\n        with self.output().open('w') as out_file:\r\n            for artist, count in artist_count.iteritems():\r\n                print >> out_file, artist, count\r\n```\r\n\r\nOptimizition notes:\r\n\r\n1. luiti's task class is built in with `date_value` property, and converted\r\n  into `Arrow` data type.\r\n2. In ArtistStreamDay, `date_str` is transformed from `date_value`, and\r\n  converted from a function into a instance property after the first call.\r\n3. `@luigi.ref_tasks` bind ArtistStreamDay as AggregateArtistsWeek's\r\n  instance property, so we can use `self.ArtistStreamDay(d1)` form to\r\n  instantiate some task instances.\r\n4. After AggregateArtistsWeek is inherited from `TaskWeek`, it'll has\r\n  `self.days_in_week` property automatically.\r\n5. `TargetUtils.line_read` replaced original function that needs two\r\n  lines codes to complete the feature, and return a Generator directly.\r\n\r\n\r\n#### Writing MapReduce in luiti\r\n* MapReduce file: `artist_project/luiti_tasks/aggregate_artists_week.py`\r\n\r\n```python\r\nfrom luiti import *\r\n\r\n@luigi.ref_tasks(\"ArtistStreamDay')\r\nclass AggregateArtistsWeek(TaskWeekHadoop):\r\n\r\n    def requires(self):\r\n        return [self.ArtistStreamDay(d1) for d1 in self.days_in_week]\r\n\r\n    def output(self):\r\n        return TargetUtils.hdfs(\"/data/weeks/artist_streams_%s.tsv\" % self.date_str\r\n\r\n    def mapper(self, line1):\r\n        timestamp, artist, track = line.strip().split()\r\n        yield artist, 1\r\n\r\n    def reducer(self, artist, counts):\r\n        yield artist, len(counts)\r\n```\r\n\r\nYes, it's almost no difference to luigi, except the `self.days_in_week`\r\nproperty and `@luigi.ref_tasks` decorator.\r\n\r\n\r\nInstall\r\n------------------------\r\n```bash\r\npip install luiti\r\n```\r\n\r\nOr lastest source code\r\n\r\n```bash\r\ngit clone https://github.com/17zuoye/luiti.git\r\ncd luiti\r\npython setup.py install\r\n```\r\n\r\n\r\nluiti command tool\r\n------------------------\r\nAfter installed package, you can use `luiti` command tool that contained\r\nin the package.\r\n\r\n```text\r\n$ luiti\r\nusage: luiti [-h] {ls,new,generate,info,clean,run} ...\r\n\r\nLuiti tasks manager.\r\n\r\noptional arguments:\r\n  -h, --help            show this help message and exit\r\n\r\nsubcommands:\r\n  valid subcommands\r\n\r\n  {ls,new,generate,info,clean,run}\r\n    ls                  list all current luiti tasks.\r\n    new                 create a new luiti project.\r\n    generate            generate a new luiti task python file.\r\n    info                show a detailed task.\r\n    clean               manage files that outputed by luiti tasks.\r\n    run                 run a luiti task.\r\n```\r\n\r\nCore concepts based on time management\r\n------------------------\r\n### date type\r\n\r\n#### Basic inheriting task classes:\r\n0. TaskBase           (luigi.Task)\r\n1. TaskHour           (TaskBase)\r\n2. TaskDay            (TaskBase)\r\n3. TaskWeek           (TaskBase)\r\n4. TaskMonth          (TaskBase)\r\n5. TaskRange          (TaskBase)\r\n\r\nYou can extend more date type by subclass `TaskBase`, and make sure the\r\ndate types are added in `TaskBase.DateTypes` too.\r\n\r\n#### Hadoop ineriting task classes:\r\n1. TaskDayHadoop      (luigi.hadoop.HadoopExt, TaskDay)\r\n2. TaskWeekHadoop     (luigi.hadoop.HadoopExt, TaskWeek)\r\n3. TaskRangeHadoop    (luigi.hadoop.HadoopExt, TaskRange)\r\n\r\n#### Other task classes:\r\n1. RootTask           (luiti.Task)\r\n2. StaticFile         (luiti.Task)\r\n3. MongoImportTask    (TaskBase)  # export json file from hdfs to mongodb.\r\n\r\n\r\n### Time library\r\n\r\nThe time library is [Arrow](http://crsmithdev.com/arrow/) , every Task\r\ninstance's `date_value` property is a arrow.Arrow type.\r\n\r\nluiti will convert date paramters into local time zone automatically. If\r\nyou want to customize time, please prefer to use\r\n `ArrowParameter.get(*strs)` and `ArrowParameter.now()` to make sure you\r\n use the local time zone.\r\n\r\n\r\nTask specification and built-in properties and recommendation\r\n------------------------\r\n### Task Naming conventions\r\n1. One Task class per file.\r\n2. Task class should be camel case ( e.g. `EnglishStudentAllExamWeek`), file name should be low case with underscore ( e.g.  `english_student_all_exam_week.py` ).\r\n3. Task files should be under the directory of `luiti_tasks`. luiti use this convertion to linking tasks inner and outer of pacakges.\r\n4. Task class name should be ended with date type, e.g. Day, Week, etc.  Please refer to `TaskBase.DateTypes`.\r\n\r\n\r\n### Task builtin properties.\r\n1. `date_value`. Required, even it's a Range type Task. This ensure that `output` will be written to a day directory.\r\n2. `data_file`. The absolute output file path, it's a string format.\r\n3. `data_dir`. The directory of the absolute output file path, it's a string format.\r\n4. `root_dir`. The root path of this package. `data_file` and `data_dir` are all under it.\r\n5. `output`. Basic Task's output class is LocalTarget, and Hadoop Task's output class is hdfs.HdfsTarget.\r\n6. `date_str`. A datetime string, such as \"20140901\".\r\n7. `date_type`. A string that generated from task class name, e.g. Day, Week, etc.\r\n8. `date_value_by_type_in_last`. If current date type is Week, and it'll return the previous week's `date_value`.\r\n8. `date_value_by_type_in_begin`. If current date type is Week, and it'll return Monday zero clock in the current week.\r\n9. `date_value_by_type_in_end`. If current date type is Week, and it'll return Sunday 11:59:59 clock in the current week.\r\n10. `pre_task_by_self`. Usually it returns previous task in the current date type. If reaches the time boundary of current date type, it returns RootTask.\r\n11. `is_reach_the_edge`. It's semester at 17zuoye business.\r\n12. `instances_by_date_range`. Class function, return all task intances list that belongs to current date range.\r\n13. `task_class`. Return current task class.\r\n\r\n\r\n### Task recommendation\r\n\r\n#### Cache\r\nWe highly recommend you to use `cached_property`, like\r\n[werkzeug](http://werkzeug.pocoo.org/docs/0.10/utils/) said, \"A decorator that\r\nconverts a function into a lazy property. The function wrapped is called\r\nthe first time to retrieve the result and then that calculated result is\r\nused the next time you access the value\".\r\n\r\nThis function is heavily used in 17zuoye everyday, we use it to cache\r\nlots of things, such as a big data dict.\r\n\r\n```python\r\nclass AnotherBussinessDay(TaskDayHadoop):\r\n\r\n    def requires(self):\r\n        return [task1, task2, ...]\r\n\r\n    def mapper(self, line1):\r\n        k1, v1 = process(line1)\r\n        yield k1, v1\r\n\r\n    def reducer(self, k1, vs1):\r\n        for v1 in vs1:\r\n            v2 = func2(v1, self.another_dict)\r\n            yield k1, v2\r\n\r\n    @cached_property\r\n    def another_dict(self):\r\n        # lots of cpu/io\r\n        return big_dict\r\n```\r\n\r\n#### Global utilities.\r\n1. Basic utilities, such as os, re, json, defaultdict, etc.\r\n2. Date processing utilities, they are arrow, ArrowParameter.\r\n3. Cache utilities, `cached_property`.\r\n4. Other utilities, such as IOUtils, DateUtils, TargetUtils, HDFSUtils, MRUtils, MathUtils,\r\n     CommandUtils, CompressUtils.\r\n\r\n\r\nTask decorators\r\n------------------------\r\n```python\r\n# 1. Bind related tasks lazily, and can be used as instance property directly.\r\n@luigi.ref_tasks(*tasks)\r\n\r\n# 2. Check current task' data source's date range is satisfied.\r\n@luigi.check_date_range()\r\n\r\n# 3. Check current task can be runned in current date range.\r\n@luigi.check_runtime_range(hour_num=[4,5,6], weekday_num=[1])\r\n\r\n# 4. Bind other output file names except for the default `date_file`, and compacts with cleaning temporary files is the task is failed.\r\n@luigi.persist_files(*files)\r\n\r\nclass AnotherBussinessDay(TaskDayHadoop):\r\n    pass\r\n```\r\n\r\n\r\n\r\nMapReduce related\r\n------------------------\r\n#### Clean temporary file when a task fails.\r\nWhen executing a MR job, luigi will write result to a file with\r\ntimestamp instantly. If the task successes, then rename to the name that\r\nthe task's original output file path. If the task fails, then YARN will\r\ndelete the temporary file automatically.\r\n\r\n#### Read file in a Generator way.\r\n1. Original way. `for line1 in TargetUtils.line_read(hdfs1)`, `line1` is an\r\n  unicode type.\r\n2. Read by JSON. `for json1 in TargetUtils.json_read(hdfs1)`, `json1` is\r\n  a valid Python object.\r\n3. Read in a K-V format. `for k1, v1 in TargetUtils.mr_read(hdfs1)`, `k1`\r\n  is an unicode type, and `v1` is a Python object.\r\n\r\n#### HDFS file object\r\nWe recommend to use `TargetUtils.hdfs(path1)`. This function compacts\r\nwith the MR file result data format that consists by \"part-00000\" file blocks.\r\n\r\n\r\n#### MapReduce test cases\r\n\r\n1. Add MapReduce input and output to `mrtest_input` and `mrtest_output`,\r\n  these mimic the MapReduce processing.\r\n2. In your test file, use `@MrTestCase` to decorator your test class,\r\n  and add your task class to `mr_task_names` list.\r\n3. (Optional) Add some config dict to `mrtest_attrs` to mimic properties\r\n  that generated in production mode.\r\n4. Run your test cases!\r\n\r\nbuy_fruit_day.py\r\n\r\n```python\r\nfrom luiti import *\r\n\r\nclass BuyFruitDay(TaskDayHadoop):\r\n\r\n    def requries(self):\r\n        ...\r\n\r\n    def output(self):\r\n        ...\r\n\r\n    def mapper(self, line):\r\n        ...\r\n        yield uid, fruit\r\n\r\n    def reducer(self, uid, fruits):\r\n        price = sum([self.price_dict[fruit] for fruit in fruits])\r\n        yield \"\", MRUtils.str_dump({\"uid\": uid, \"price\": price})\r\n\r\n    @cache_property\r\n    def price_dict(self):\r\n        result = dict()\r\n        for json1 in TargetUtils.json_read(a_fruit_price_list_file):\r\n            result[json1[\"name\"]] = json1[\"price\"]\r\n        return result\r\n\r\n    def mrtest_input(self):\r\n        return \"\"\"\r\n{\"uid\": 3, \"fruit\": \"Apple\"}\r\n{\"uid\": 3, \"fruit\": \"Apple\"}\r\n{\"uid\": 3, \"fruit\": \"Banana\"}\r\n        \"\"\"\r\n\r\n    def mrtest_output(self):\r\n        return \"\"\"\r\n{\"uid\": 3, \"price\": 7}\r\n        \"\"\"\r\n\r\n    def mrtest_attrs(self):\r\n        return {\r\n          \"price_dict\": {\r\n            \"Apple\": 3,\r\n            \"Banana\": 1,\r\n          }\r\n        }\r\n\r\n```\r\n\r\ntest file\r\n```python\r\nfrom luiti import MrTestCase\r\n\r\n@MrTestCase\r\nclass TestMapReduce(unittest.TestCase):\r\n    mr_task_names = [\r\n            'ClassEnglishAllExamWeek',\r\n            ...\r\n           ]\r\n\r\nif __name__ == '__main__':\r\n  unittest.main()\r\n```\r\n\r\n\r\nManage multiple projects in luiti\r\n------------------------\r\n#### The directory structure of a specific project.\r\n\r\nWe recommend you to organize every project's directory structure as the\r\nbelow form, and it means it's also a normal Python package, for example:\r\n\r\n```text\r\nproject_A                                            --- project directory\r\n  setup.py                                           --- Python package install script\r\n  README.markdown                                    --- project README\r\n  project_A/                                         --- Python package install directory\r\n  ├── __init__.py                                    --- mark current directories on disk as a Python package directories\r\n  └── luiti_tasks                                    --- a directory name which indicates it contains several luiti tasks\r\n      ├── __init__.py                                --- mark current directories on disk as a Python package directories\r\n      ├── __init_luiti.py                            --- initialize luiti environment variables\r\n      ├── exam_logs_english_app_day.py               --- an example luiti task\r\n      ├── ..._day.py                                 --- another example luiti task\r\n      └── templates                                  --- some libraries\r\n            ├── __init__.py\r\n            └── ..._template.py\r\n```\r\n\r\nAfter installing `luiti`, you can run following command line to generate\r\na project like above.\r\n```bash\r\nluiti new project_A\r\n```\r\n\r\nIf other luiti projects needs to using this package, and you need to\r\ninstall this package, to make sure luiti could find them in the\r\nsearch path (`sys.path`) of Python modules.\r\n\r\n\r\n#### How to link current Task to another Task that belongs to another pacakge?\r\nEvery luiti projects share the same structure, e.g.\r\n`project_A/luiti_tasks/another_feature_day.py`. After config\r\n`luigi.plug_packages(\"project_B\", \"project_C==0.0.2\"])` in\r\n`__init_luiti.py`, you can use `@luigi.ref_tasks(\"ArtistStreamDay')` to\r\nindicate current Task to find `ArtistStreamDay` Task in current package\r\n`project_A`, or related `project_B`, `project_C` packages.\r\n\r\n\r\nExtend luiti\r\n------------------------\r\nUsing `TaskBase`'s builtin `extend` class function to extend or overwrite\r\nthe default properties or functions, for example:\r\n\r\n```python\r\nTaskWeek.extend({\r\n    'property_1' : lambda self: \"property_2\",\r\n})\r\n```\r\n\r\n`extend` class function compacts with `function`, `property`, `cached_property`,\r\nor any other attributes at the same time。When you want to overwrite\r\n`property` and `cached_property`, you just need a function value, and\r\n`extend` will automatically converted into `property` and\r\n`cached_property` type.\r\n\r\n\r\nFAQ\r\n------------------------\r\nQ: How atomic file is supported?\r\n\r\nA: As luigi's document mentioned that \"Simple class that writes to a temp file and moves it on close()\r\n    Also cleans up the temp file if close is not invoked\", so use the `self.input().open(\"r\")` or\r\n    `self.output().open(\"w\")` instead of `open(\"some_file\", \"w\")`.\r\n\r\nQ: Can luigi detect the interdependent tasks?\r\n\r\nA: It's not question inside of luigi, but it's a question about [topological sorting](https://en.wikipedia.org/wiki/Topological_sorting)\r\n   as a general computer science topic. The task scheduler is implemented at `luigi/scheduler.py` .\r\n\r\nQ: How to pass more parameters into luiti tasks?\r\n\r\nA: You can create a key-value dict, `date_value` is the key, and your\r\ncustomize parameters are the values.\r\n\r\n\r\n\r\nIf you have other unresolved questions, please feel free to ask\r\nquestions at [issues](https://github.com/17zuoye/luiti/issues).\r\n\r\n\r\nRun tests\r\n------------------------\r\n```bash\r\n./tests/run.sh\r\n```\r\n\r\nLicense\r\n------------------------\r\nMIT. David Chen @ 17zuoye.\r\n","google":"UA-57207964-1","note":"Don't delete this file! It's used internally to help with page regeneration."}